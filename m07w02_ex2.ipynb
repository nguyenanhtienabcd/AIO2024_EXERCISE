{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenanhtienabcd/AIO2024_EXERCISE/blob/feature%2FMODULE7-WEEK2/m07w02_ex2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uovdyNAQHyu7"
      },
      "source": [
        "## Classification + Bounding Box Regession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KlSh0t3HrXi",
        "outputId": "985c3aa8-89a0-4618-b0df-772fcbc1ceb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXLayhqld6T0",
        "outputId": "f050f320-c962-46ac-f980-12c48a33647b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/andrewmvd/dog-and-cat-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.03G/1.03G [00:21<00:00, 50.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/andrewmvd/dog-and-cat-detection/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "data_dir = kagglehub.dataset_download(\"andrewmvd/dog-and-cat-detection\")\n",
        "print('Path to dataset files:', data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ulHQPpojjPS_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.models.resnet import ResNet18_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RbobIa3Ejw3T"
      },
      "outputs": [],
      "source": [
        "from genericpath import isfile\n",
        "# định nghĩa một lớp class image mới\n",
        "class ImageDataset(Dataset):\n",
        "\n",
        "  #------ khởi tạo dữ liệu---------\n",
        "  def __init__(self, annotations_dir, image_dir, transform = None):\n",
        "    self.annotations_dir = annotations_dir\n",
        "    self.image_dir = image_dir\n",
        "    self.transform = transform\n",
        "    self.image_files = self.filter_image_with_multiple_objects()\n",
        "\n",
        "  #------ lọc dữ liệu---------\n",
        "  def filter_image_with_multiple_objects(self):\n",
        "    # tạo một list chứa các file thỏa mãn\n",
        "    valid_image_files = []\n",
        "    for f in os.listdir(self.image_dir):\n",
        "      if os.path.isfile(os.path.join(self.image_dir, f)):\n",
        "        img_name = f\n",
        "        # mục đích của đoạn code này là chia file thành 2 phần\n",
        "        # [file name, extention] => [0] là lấy file name\n",
        "        annotation_name = img_name.split('.')[0] + '.xml'\n",
        "        annotation_path = os.path.join(self.annotations_dir, annotation_name)\n",
        "\n",
        "        # tạo một hàm dữ lại các ảnh có object đơn\n",
        "        if self.count_objects_in_annotation(annotation_path) ==1:\n",
        "          valid_image_files.append(img_name)\n",
        "        else:\n",
        "          print(f'Image {img_name} has multiple objects and will be excluded the dataset')\n",
        "    return valid_image_files\n",
        "\n",
        "   #------ đếm đối tượng---------\n",
        "  def count_objects_in_annotation(self, annotation_path):\n",
        "    try:\n",
        "      tree = ET.parse(annotation_path) # đọc file xml từ path\n",
        "      root = tree.getroot() # lấy phần gốc của file xml\n",
        "      count = 0\n",
        "      for obj in root.findall('object'):\n",
        "        count += 1\n",
        "      return count\n",
        "    except Exception as e:\n",
        "      print(f'Error reading annotation file {annotation_path}: {e}')\n",
        "      return 0\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_files)\n",
        "\n",
        "  #------ lấy mẫu---------\n",
        "  def __getitem__(self, idx):\n",
        "    # đường dẫn ảnh\n",
        "    img_name = self.image_files[idx]\n",
        "    img_path = os.path.join(self.image_dir, img_name)\n",
        "\n",
        "    # load ảnh lên\n",
        "    image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "    # annotation path\n",
        "    annotation_name = img_name.split('.')[0] + '.xml'\n",
        "    annotation_path = os.path.join(self.annotations_dir, annotation_name)\n",
        "\n",
        "    # Parse annotation\n",
        "    label, bbox = self.parse_annotation(annotation_path)\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    return image, label, bbox\n",
        "\n",
        "    #------ phân tích annotations---------\n",
        "  def parse_annotation(self, annotation_path): # un-indent this method\n",
        "      tree = ET.parse(annotation_path)\n",
        "      root = tree.getroot()\n",
        "\n",
        "      # lấy kích thước của ảnh để chuẩn hóa\n",
        "      image_width = int(root.find('size').find('width').text)\n",
        "      image_height = int(root.find('size').find('height').text)\n",
        "\n",
        "      label = None\n",
        "      bbox = None\n",
        "\n",
        "      for obj in root.findall('object'):\n",
        "        name = obj.find('name').text\n",
        "        if (label is None):\n",
        "          # lấy label đầu tiên\n",
        "          label = name\n",
        "\n",
        "          # lấy thông tin về bounding box\n",
        "          xmin = int(obj.find('bndbox/xmin').text)\n",
        "          ymin = int(obj.find('bndbox/ymin').text)\n",
        "          xmax = int(obj.find('bndbox/xmin').text)\n",
        "          ymax = int(obj.find('bndbox/ymin').text)\n",
        "\n",
        "          # chuẩn hóa bounding box trong khoảng từ [0,1]\n",
        "          bbox = [xmin/image_width,\n",
        "                  ymin/image_height,\n",
        "                  xmax/image_width,\n",
        "                  ymax/image_height]\n",
        "\n",
        "        label_num = 0 if label == 'cat' else 1 if label == 'dog' else -1\n",
        "        return label_num, torch.tensor(bbox, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TqXHWS3IQZPI"
      },
      "outputs": [],
      "source": [
        "annotations_dir = os.path.join(data_dir, 'annotations')\n",
        "image_dir = os.path.join(data_dir, 'images')\n",
        "\n",
        "image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
        "df = pd.DataFrame({'image_name': image_files})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qSycZ6OyRo1O"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.125, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSd8WeBfS5LQ",
        "outputId": "32fb7824-c003-4fb9-9daf-a8af78f005df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Cats_Test736.png has multiple objects and will be excluded the dataset\n",
            "Image Cats_Test736.png has multiple objects and will be excluded the dataset\n",
            "Image Cats_Test736.png has multiple objects and will be excluded the dataset\n"
          ]
        }
      ],
      "source": [
        "# transform và chuyển dữ liệu sang tensor\n",
        "from torchvision import transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "#train_dataset, val_dataset, test_dataset có cùng một tệp dữ liệu\n",
        "train_dataset = ImageDataset(annotations_dir, image_dir, transform)\n",
        "val_dataset = ImageDataset(annotations_dir, image_dir, transform)\n",
        "test_dataset = ImageDataset(annotations_dir, image_dir, transform)\n",
        "\n",
        "# lọc dataset\n",
        "# lọc tất cả các file nào nằm trong dataframe train, val, test\n",
        "train_dataset.image_files =  [f for f in train_dataset.image_files if f in train_df['image_name'].values]\n",
        "val_dataset.image_files =  [f for f in val_dataset.image_files if f in val_df['image_name'].values]\n",
        "test_dataset.image_files =  [f for f in test_dataset.image_files if f in test_df['image_name'].values]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4h14_f21TTuA"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ne3azjibXwkO"
      },
      "outputs": [],
      "source": [
        "class TwoHeadeModel(nn.Module):\n",
        "  def __init__(self, num_classes = 2):\n",
        "    super(TwoHeadeModel, self).__init__()\n",
        "    self.base_model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "    # lất layer cuối cùng ra\n",
        "    self.num_ftrs = self.base_model.fc.in_features\n",
        "    # thay đổi layer cuối cùng\n",
        "    self.base_model.fc = nn.Identity()\n",
        "\n",
        "    # xóa toàn bộ trọng số của layer cuối cùng, sau đó tuning lại\n",
        "    self.classifier = nn.Linear(self.num_ftrs, num_classes)\n",
        "\n",
        "    # bounding box head (x_min, y_min, x_max, y_max)\n",
        "    self.bbox_regressor = nn.Linear(self.num_ftrs, 4)\n",
        "\n",
        "  def forward(self, x):\n",
        "    base_out = self.base_model(x)\n",
        "    class_out = self.classifier(base_out)\n",
        "    # tại vì ban đầu mình đã normalize trong khoảng (0,1)\n",
        "    bbox_out = torch.sigmoid(self.bbox_regressor(base_out))\n",
        "\n",
        "    return class_out, bbox_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJcQno2jrjoJ"
      },
      "source": [
        "Cài đặt cho model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpg31noFrlkd",
        "outputId": "8da7987d-3ae8-4aec-d824-4c43da1feb5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 186MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = TwoHeadeModel()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion_class = nn.CrossEntropyLoss()\n",
        "criterion_bbox = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lQp6mzKtYLO",
        "outputId": "fe3ffa72-fb1e-46ec-b86d-22b264688930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Validation Accuracy : 90.79%,Avg. Bbox Loss : 0.0157\n",
            "Epoch 2/10, Validation Accuracy : 66.94%,Avg. Bbox Loss : 0.0111\n",
            "Epoch 3/10, Validation Accuracy : 92.41%,Avg. Bbox Loss : 0.0096\n",
            "Epoch 4/10, Validation Accuracy : 90.79%,Avg. Bbox Loss : 0.0107\n",
            "Epoch 5/10, Validation Accuracy : 88.08%,Avg. Bbox Loss : 0.0070\n",
            "Epoch 6/10, Validation Accuracy : 95.93%,Avg. Bbox Loss : 0.0065\n",
            "Epoch 7/10, Validation Accuracy : 93.77%,Avg. Bbox Loss : 0.0071\n",
            "Epoch 8/10, Validation Accuracy : 82.38%,Avg. Bbox Loss : 0.0080\n",
            "Epoch 9/10, Validation Accuracy : 94.04%,Avg. Bbox Loss : 0.0066\n",
            "Epoch 10/10, Validation Accuracy : 94.04%,Avg. Bbox Loss : 0.0069\n"
          ]
        }
      ],
      "source": [
        "# trainning loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for batch_idx, (images, labels, bboxes) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    bboxes = bboxes.to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    class_outputs, bbox_outputs = model(images)\n",
        "    loss_class = criterion_class(class_outputs, labels)\n",
        "    loss_bbox = criterion_bbox(bbox_outputs, bboxes)\n",
        "    loss = loss_class + loss_bbox # loss combination\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_sample = 0\n",
        "    total_loss_bbox = 0\n",
        "    total_loss_class = 0\n",
        "    for images, labels, bboxes in val_loader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      bboxes = bboxes.to(device)\n",
        "\n",
        "      class_outputs, bbox_outputs = model(images)\n",
        "      _, predicted = torch.max(class_outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "      # tính toán bounding box cho việc giám sát\n",
        "      loss_bbox = criterion_bbox(bbox_outputs, bboxes)\n",
        "      total_loss_bbox += loss_bbox.item() * images.size(0)\n",
        "      total_sample += images.size(0)\n",
        "\n",
        "    avg_loss_bbox = total_loss_bbox / total_sample\n",
        "    print (f'Epoch {epoch+1}/{num_epochs}, Validation Accuracy : {float(correct)/ float(total) *100:.2f}%,'\n",
        "            f'Avg. Bbox Loss : { avg_loss_bbox :.4f}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "3iiR1KuE0nRV",
        "outputId": "c827e80e-c1f2-4885-fc00-125a45ca1f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 94.30%, Avg. Bbox Loss: 0.0063\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# prompt: kiểm tra dữ liệu với tệp test\n",
        "\n",
        "# Assuming 'test_dataset' and 'test_loader' are defined as in the provided code.\n",
        "\n",
        "# Evaluation on the test set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_sample = 0\n",
        "    total_loss_bbox = 0\n",
        "    total_loss_class = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    for images, labels, bboxes in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        bboxes = bboxes.to(device)\n",
        "\n",
        "        class_outputs, bbox_outputs = model(images)\n",
        "        _, predicted = torch.max(class_outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate bounding box loss for monitoring\n",
        "        loss_bbox = criterion_bbox(bbox_outputs, bboxes)\n",
        "        total_loss_bbox += loss_bbox.item() * images.size(0)\n",
        "        total_sample += images.size(0)\n",
        "\n",
        "    avg_loss_bbox = total_loss_bbox / total_sample\n",
        "    accuracy = float(correct) / float(total) * 100\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%, Avg. Bbox Loss: {avg_loss_bbox:.4f}')\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['cat', 'dog'], yticklabels=['cat', 'dog'])\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Assuming you have a test_loader and model as defined in your previous code\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels, bboxes in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels, bboxes = labels.to(device), bboxes.to(device)\n",
        "        class_outputs, bbox_outputs = model(images)\n",
        "        _, predicted = torch.max(class_outputs, 1)\n",
        "\n",
        "        for i in range(images.shape[0]):  # Iterate through each image in the batch\n",
        "            image = images[i].permute(1, 2, 0).cpu().numpy()  # Convert image tensor to numpy array\n",
        "            image = (image * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406]) #denormalize\n",
        "            image = np.clip(image,0,1) # clip image to valid range\n",
        "\n",
        "            true_label = labels[i].item()\n",
        "            predicted_label = predicted[i].item()\n",
        "\n",
        "            true_bbox = bboxes[i].cpu().numpy()\n",
        "            predicted_bbox = bbox_outputs[i].cpu().numpy()\n",
        "\n",
        "\n",
        "            fig, ax = plt.subplots(1)\n",
        "            ax.imshow(image)\n",
        "\n",
        "            # True bounding box\n",
        "            true_width = true_bbox[2] - true_bbox[0]\n",
        "            true_height = true_bbox[3] - true_bbox[1]\n",
        "            true_rect = patches.Rectangle((true_bbox[0]*224, true_bbox[1]*224), true_width *224, true_height*224, linewidth=2, edgecolor='g', facecolor='none')\n",
        "\n",
        "            # Predicted bounding box\n",
        "            predicted_width = predicted_bbox[2] - predicted_bbox[0]\n",
        "            predicted_height = predicted_bbox[3] - predicted_bbox[1]\n",
        "            predicted_rect = patches.Rectangle((predicted_bbox[0]*224, predicted_bbox[1]*224), predicted_width*224, predicted_height*224, linewidth=2, edgecolor='r', facecolor='none')\n",
        "\n",
        "            ax.add_patch(true_rect)\n",
        "            ax.add_patch(predicted_rect)\n",
        "\n",
        "            ax.set_title(f'True: {true_label}, Predicted: {predicted_label}')\n",
        "            plt.show()\n",
        "\n",
        "            #break  # remove this line to visualize all images in a batch\n",
        "        #break # remove this line to visualize all batches\n",
        "\n"
      ],
      "metadata": {
        "id": "3fQQntcs-dzn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMDYlcNBz/BRLA3FYv8ilo6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}