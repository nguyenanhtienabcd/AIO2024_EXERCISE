{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWuGC3GXBPC0"
      },
      "source": [
        "## Condition GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHhSLQlWBSxY"
      },
      "source": [
        "### Chuẩn bị data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fo43rYtsIhgh"
      },
      "outputs": [],
      "source": [
        "# import các thu viện cần thiết\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import numpy as np\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYHlF3wsIm_4",
        "outputId": "6e945f8c-2f2b-4fef-af90-6676e4e86792"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:39<00:00, 249kB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 115kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:09<00:00, 178kB/s] \n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 883kB/s]\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "image_size = 32\n",
        "num_classes = 10\n",
        "transforms = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "dataset = datasets.MNIST(root='data', train=True, transform=transforms, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-vV4HDbyADdj"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMOTE_0_B3tj",
        "outputId": "1b948cae-50d4-4882-fc64-0a0fff0e6839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size: torch.Size([32, 1, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# Lấy một batch từ data_loader\n",
        "images, labels = next(iter(data_loader))\n",
        "\n",
        "# In kích thước của batch và ảnh\n",
        "print(f\"Batch size: {images.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4HUHnYbdKT5"
      },
      "source": [
        "### Xây dựng model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nawjxVZcdKT5"
      },
      "outputs": [],
      "source": [
        "# xây dựng Generator bằng MLP\n",
        "# layer cuối gần cuối có 1024 neuron, layer cuối cùng có ảnh có kích thước 64x64\n",
        "# reshape lại ảnh thành 64x64 (1 channel)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, image_shape, num_classes, embedding_dim, latent_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        self.label_embedding = nn.Embedding(num_classes, embedding_dim)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim + embedding_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Linear(1024, int(np.prod(image_shape))),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z: Tensor, labels) -> Tensor:\n",
        "        label_embed = self.label_embedding(labels)\n",
        "        input = torch.cat((z, label_embed), dim=1)\n",
        "        output = self.model(input)\n",
        "        output = output.view(output.size(0), *image_shape)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YgwfL41fdKT5"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, image_shape, num_classes, embedding_dim, latent_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.label_embedding = nn.Embedding(num_classes, embedding_dim)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(image_shape)) + embedding_dim, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor, labels) -> Tensor:\n",
        "        output = x.view(x.size(0), -1)\n",
        "        label_embed = self.label_embedding(labels)\n",
        "        output = torch.cat((output, label_embed), dim=1)\n",
        "        output = self.model(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M5OPpv5-woV"
      },
      "source": [
        "### Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uoJ-gv30_v2Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('images', exist_ok=True)\n",
        "\n",
        "save_interval = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SNb43gQPAvYZ"
      },
      "outputs": [],
      "source": [
        "images_batch, labels = next(iter(data_loader))\n",
        "embedding_dim = 16\n",
        "latent_dim = 100\n",
        "image_channels = images_batch.size(1) #1\n",
        "image_shape = (image_channels, image_size, image_size)\n",
        "generator = Generator(image_shape, num_classes, embedding_dim, latent_dim).to(device)\n",
        "discriminator = Discriminator(image_shape, num_classes, embedding_dim, latent_dim).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sTL3NX9I_6dn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/150: 100%|██████████| 1875/1875 [00:41<00:00, 45.64batch/s]\n",
            "Epoch 2/150: 100%|██████████| 1875/1875 [00:38<00:00, 48.69batch/s]\n",
            "Epoch 3/150: 100%|██████████| 1875/1875 [00:53<00:00, 35.34batch/s]\n",
            "Epoch 4/150: 100%|██████████| 1875/1875 [01:00<00:00, 30.92batch/s]\n",
            "Epoch 5/150: 100%|██████████| 1875/1875 [00:50<00:00, 37.15batch/s]\n",
            "Epoch 6/150: 100%|██████████| 1875/1875 [00:30<00:00, 61.19batch/s]\n",
            "Epoch 7/150: 100%|██████████| 1875/1875 [00:36<00:00, 52.04batch/s]\n",
            "Epoch 8/150: 100%|██████████| 1875/1875 [00:35<00:00, 53.08batch/s]\n",
            "Epoch 9/150: 100%|██████████| 1875/1875 [00:43<00:00, 43.33batch/s]\n",
            "Epoch 10/150: 100%|██████████| 1875/1875 [00:43<00:00, 43.10batch/s]\n",
            "Epoch 11/150: 100%|██████████| 1875/1875 [00:39<00:00, 47.05batch/s]\n",
            "Epoch 12/150: 100%|██████████| 1875/1875 [01:00<00:00, 30.82batch/s]\n",
            "Epoch 13/150: 100%|██████████| 1875/1875 [01:01<00:00, 30.31batch/s]\n",
            "Epoch 14/150: 100%|██████████| 1875/1875 [01:01<00:00, 30.64batch/s]\n",
            "Epoch 15/150: 100%|██████████| 1875/1875 [01:02<00:00, 29.86batch/s]\n",
            "Epoch 16/150: 100%|██████████| 1875/1875 [01:21<00:00, 23.10batch/s]\n",
            "Epoch 17/150: 100%|██████████| 1875/1875 [01:30<00:00, 20.65batch/s]\n",
            "Epoch 18/150: 100%|██████████| 1875/1875 [01:54<00:00, 16.44batch/s]\n",
            "Epoch 19/150: 100%|██████████| 1875/1875 [01:27<00:00, 21.43batch/s]\n",
            "Epoch 20/150: 100%|██████████| 1875/1875 [00:54<00:00, 34.60batch/s]\n",
            "Epoch 21/150: 100%|██████████| 1875/1875 [00:51<00:00, 36.74batch/s]\n",
            "Epoch 22/150: 100%|██████████| 1875/1875 [01:09<00:00, 27.14batch/s]\n",
            "Epoch 23/150: 100%|██████████| 1875/1875 [01:10<00:00, 26.66batch/s]\n",
            "Epoch 24/150: 100%|██████████| 1875/1875 [01:02<00:00, 30.08batch/s]\n",
            "Epoch 25/150: 100%|██████████| 1875/1875 [01:04<00:00, 29.21batch/s]\n",
            "Epoch 26/150: 100%|██████████| 1875/1875 [00:52<00:00, 35.54batch/s]\n",
            "Epoch 27/150: 100%|██████████| 1875/1875 [00:51<00:00, 36.71batch/s]\n",
            "Epoch 28/150: 100%|██████████| 1875/1875 [01:05<00:00, 28.72batch/s]\n",
            "Epoch 29/150: 100%|██████████| 1875/1875 [01:11<00:00, 26.24batch/s]\n",
            "Epoch 30/150: 100%|██████████| 1875/1875 [00:55<00:00, 33.77batch/s]\n",
            "Epoch 31/150: 100%|██████████| 1875/1875 [00:56<00:00, 32.96batch/s]\n",
            "Epoch 32/150: 100%|██████████| 1875/1875 [00:55<00:00, 33.92batch/s]\n",
            "Epoch 33/150: 100%|██████████| 1875/1875 [00:54<00:00, 34.57batch/s]\n",
            "Epoch 34/150: 100%|██████████| 1875/1875 [00:52<00:00, 35.64batch/s]\n",
            "Epoch 35/150: 100%|██████████| 1875/1875 [00:56<00:00, 33.46batch/s]\n",
            "Epoch 36/150: 100%|██████████| 1875/1875 [00:52<00:00, 36.03batch/s]\n",
            "Epoch 37/150: 100%|██████████| 1875/1875 [00:51<00:00, 36.50batch/s]\n",
            "Epoch 38/150: 100%|██████████| 1875/1875 [00:52<00:00, 35.82batch/s]\n",
            "Epoch 39/150: 100%|██████████| 1875/1875 [00:50<00:00, 37.30batch/s]\n",
            "Epoch 40/150: 100%|██████████| 1875/1875 [00:49<00:00, 37.82batch/s]\n",
            "Epoch 41/150: 100%|██████████| 1875/1875 [00:47<00:00, 39.61batch/s]\n",
            "Epoch 42/150: 100%|██████████| 1875/1875 [00:47<00:00, 39.11batch/s]\n",
            "Epoch 43/150: 100%|██████████| 1875/1875 [00:48<00:00, 38.56batch/s]\n",
            "Epoch 44/150: 100%|██████████| 1875/1875 [00:45<00:00, 40.86batch/s]\n",
            "Epoch 45/150: 100%|██████████| 1875/1875 [00:44<00:00, 42.06batch/s]\n",
            "Epoch 46/150: 100%|██████████| 1875/1875 [00:46<00:00, 40.10batch/s]\n",
            "Epoch 47/150: 100%|██████████| 1875/1875 [00:45<00:00, 40.78batch/s]\n",
            "Epoch 48/150: 100%|██████████| 1875/1875 [00:44<00:00, 42.52batch/s]\n",
            "Epoch 49/150: 100%|██████████| 1875/1875 [00:45<00:00, 41.12batch/s]\n",
            "Epoch 50/150: 100%|██████████| 1875/1875 [00:48<00:00, 38.51batch/s]\n",
            "Epoch 51/150: 100%|██████████| 1875/1875 [00:45<00:00, 41.41batch/s]\n",
            "Epoch 52/150: 100%|██████████| 1875/1875 [00:45<00:00, 40.97batch/s]\n",
            "Epoch 53/150: 100%|██████████| 1875/1875 [00:49<00:00, 38.03batch/s]\n",
            "Epoch 54/150: 100%|██████████| 1875/1875 [01:07<00:00, 27.96batch/s]\n",
            "Epoch 55/150:   0%|          | 8/1875 [00:08<32:19,  1.04s/batch]  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     31\u001b[0m g_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 32\u001b[0m \u001b[43moptimizer_G\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m############ Discriminator ##########\u001b[39;00m\n\u001b[0;32m     36\u001b[0m real_dis_output \u001b[38;5;241m=\u001b[39m discriminator(imgs, labels)\n",
            "File \u001b[1;32mc:\\Users\\lamxu\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lamxu\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
            "File \u001b[1;32mc:\\Users\\lamxu\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\optim\\adam.py:244\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    232\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    234\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    235\u001b[0m         group,\n\u001b[0;32m    236\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    241\u001b[0m         state_steps,\n\u001b[0;32m    242\u001b[0m     )\n\u001b[1;32m--> 244\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "File \u001b[1;32mc:\\Users\\lamxu\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\lamxu\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\optim\\adam.py:876\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    874\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 876\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "EPOCHS = 150\n",
        "\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0001)\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "g_losses, d_losses = [], []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  with tqdm(total=len(data_loader), desc=f\"Epoch {epoch+1}/{EPOCHS}\", unit=\"batch\") as pbar:\n",
        "    for i, (imgs,labels) in enumerate(data_loader):\n",
        "\n",
        "      imgs = imgs.to(device)\n",
        "      real_labels = torch.ones(imgs.size(0), 1).to(device)\n",
        "      fake_labels = torch.zeros(imgs.size(0), 1).to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "\n",
        "      ############ Generator ##########\n",
        "      noise = torch.randn(imgs.size(0), latent_dim).to(device)\n",
        "\n",
        "      fake_imgs = generator(noise, labels)\n",
        "      g_dis_output = discriminator(fake_imgs, labels)\n",
        "      g_loss = criterion(g_dis_output, real_labels)\n",
        "      g_losses.append(g_loss.item())\n",
        "\n",
        "      optimizer_G.zero_grad()\n",
        "      g_loss.backward()\n",
        "      optimizer_G.step()\n",
        "\n",
        "      ############ Discriminator ##########\n",
        "\n",
        "      real_dis_output = discriminator(imgs, labels)\n",
        "      real_loss = criterion(real_dis_output, real_labels)\n",
        "\n",
        "      fake_dis_output = discriminator(fake_imgs.detach(), labels)\n",
        "      fake_loss = criterion(fake_dis_output, fake_labels)\n",
        "\n",
        "      d_loss = (real_loss + fake_loss)/2\n",
        "      d_losses.append(d_loss.item())\n",
        "\n",
        "      optimizer_D.zero_grad()\n",
        "      d_loss.backward()\n",
        "      optimizer_D.step()\n",
        "\n",
        "      # Cập nhật thanh tiến trình\n",
        "      pbar.update(1)\n",
        "\n",
        "\n",
        "\n",
        "  if epoch % save_interval == 0:\n",
        "        save_image(fake_imgs.data[:25], f\"images/epoch_{epoch}.png\", nrow=5, normalize=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MZztYm5Pxit"
      },
      "source": [
        "# 4. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRhIW3E-Pxit"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlZZLPmCPxit"
      },
      "outputs": [],
      "source": [
        "generator.eval()\n",
        "\n",
        "num_sample = 5\n",
        "for i in range(num_classes):\n",
        "    target_class = i\n",
        "    z = torch.randn((num_sample, latent_dim)).to(device)\n",
        "    condition_labels = torch.full((num_sample,), target_class, dtype=torch.long).to(device)\n",
        "\n",
        "    gen_imgs = generator(z, condition_labels).detach().cpu()\n",
        "\n",
        "    grid = make_grid(gen_imgs, nrow=num_sample, normalize=True).permute(1,2,0).numpy()\n",
        "    plt.imshow(grid)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3xA7yoLPxiv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch-gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
