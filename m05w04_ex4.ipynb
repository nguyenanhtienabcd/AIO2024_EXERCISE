{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBNmNaX8eOr0mMiuIlwBQP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenanhtienabcd/AIO2024_EXERCISE/blob/feature%2FMODULE5-WEEK4/m05w04_ex4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex4: Adam"
      ],
      "metadata": {
        "id": "Kuu4E0UgXy89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "cho một hàm số Loss ban đầu như dưới đây:\n",
        "$$f(w_1, w_2) = 0.1w_1^2 + 2w_2^2 \\;\\;\\;\\;\\;\\;\\;(1)$$ \\\\\n",
        "Giá trị khởi tạo:\n",
        "$$w1 = -5,\\; w2 = -2,\\; s1 = 0,\\; s2 = 0,\\; v_1 = 0,\\; v_2 = 0\\; α = 0.2,\\; \\beta_1 = 0.9,\\; \\beta_2 = 0.999,\\; \\epsilon = 10^{-6} $$ \\\\\n",
        "\n",
        "\n",
        "**Epoch1**:\n",
        "\n",
        "- **STEP1**: tính đạo hàm riêng cho hàm số \\\\\n",
        "$$\n",
        "\\begin{aligned}\n",
        "{f_{w_1}}^{'} = \\frac{\\partial f}{\\partial w_1} & = 2 \\cdot 0.1w_1 = 0.2w_1 = -1  \\\\\n",
        "{f_{w_2}}^{'} = \\frac{\\partial f}{\\partial w_2} & = 2 \\cdot 2w_2 = 4w_2 = -8\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- **STEP2**: cập nhật biến số của hàm v \\\\\n",
        "$$\n",
        "\\begin{aligned}\n",
        "v_1^1 &= \\beta_1 \\cdot v_1^1 + (1-\\beta_1) \\cdot \\frac{\\partial f}{\\partial w_1}  = 0.9 \\cdot 0 + 0.1\\cdot (-1) = -0.1  \\\\\n",
        "v_2^1 &= \\beta_1 \\cdot v_2^1 + (1-\\beta_1) \\cdot \\frac{\\partial f}{\\partial w_2}  = 0.9 \\cdot 0 + 0.1 \\cdot (-8) = -0.8\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- **STEP3**: cập nhật biến số của hàm s \\\\\n",
        "$$\n",
        "\\begin{aligned}\n",
        "s_1^1 &= \\beta_2 \\cdot s_1 + (1-\\beta_2) \\cdot ({f_{w_1}}^{'})^2 = 0.999 \\cdot 0  + 0.001 \\cdot (-1)^2 = 0.001 \\\\\n",
        "s_2^1 &= \\beta_2 \\cdot s_2 + (1-\\beta_2) \\cdot ({f_{w_2}}^{'})^2 = 0.999 \\cdot 0 + 0.001 \\cdot (-8)^2 = 0.064\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- **STEP4**: tính toán bias-correction \\\\\n",
        "$$\n",
        "\\begin{aligned}\n",
        "v_{1corr} &= \\frac{v_1^1}{1-({\\beta_1})^1} = \\frac{-0.1}{1-0.9} = -1\\\\\n",
        "v_{2corr} &= \\frac{v_2^1}{1-({\\beta_1})^1} = \\frac{-0.8}{1-0.9} = -8\\\\\n",
        "s_{1corr} &= \\frac{s_1^1}{1-({\\beta_1})^1} = \\frac{0.001}{1-0.999} = 1\\\\\n",
        "s_{2corr} &= \\frac{s_2^1}{1-({\\beta_1})^1} = \\frac{0.064}{1-0.999} = 64\\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- **STEP5**: cập nhật trọng số w \\\\\n",
        "$$\n",
        "\\begin{aligned}\n",
        "w_1^2 = w_1^1 - \\alpha \\cdot \\frac{v_{1\\text{corr}}}{\\sqrt[2]{s_{1\\text{corr}}} + \\epsilon} = -5 - 0.2 \\cdot \\frac{-1}{\\sqrt[2]{1} + 10^{-6}} = -5 + 0.2 = -4.8\n",
        "\\\\\n",
        "w_2^2 = w_2^1 - \\alpha \\cdot \\frac{v_{2\\text{corr}}}{\\sqrt[2]{s_{2\\text{corr}}} + \\epsilon} = -2 - 0.2 \\cdot \\frac{-8}{\\sqrt[2]{64} + 10^{-6}} = -2 + 0.2 = -1.8 \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "\n",
        "**Epoch 2**:\n",
        "\n",
        "- **STEP1**: tính đạo hàm riêng cho hàm số \\\\\n",
        "$$\n",
        "\\begin{aligned}\n",
        "{f_{w_1}}^{'} = \\frac{\\partial f}{\\partial w_1} & = 2 \\cdot 0.1w_1 = 0.2w_1 = 0.2 \\cdot (-4.8) = -0.96 \\\\\n",
        "{f_{w_2}}^{'} = \\frac{\\partial f}{\\partial w_2} & = 2 \\cdot 2w_2 = 4w_2 = 4 \\cdot (-1.8) = -7.2\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- **STEP2**: cập nhật biến số của hàm v \\\\\n",
        "$$\n",
        "\\begin{aligned}\n",
        "v_1^2 &= \\beta_1 \\cdot v_1^1 + (1-\\beta_1) \\cdot \\frac{\\partial f}{\\partial w_1} = 0.9 \\cdot (-0.1) + 0.1 \\cdot (-0.96) = -0.186 \\\\\n",
        "v_2^2 &= \\beta_1 \\cdot v_2^1 + (1-\\beta_1) \\cdot \\frac{\\partial f}{\\partial w_2} = 0.9 \\cdot (-0.8) + 0.1 \\cdot (-7.2) = -1.44\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- **STEP3**: cập nhật biến số của hàm s \\\\\n",
        "$$\n",
        "\\begin{aligned}\n",
        "s_1^2 &= \\beta_2 \\cdot s_1^1 + (1-\\beta_2) \\cdot ({f_{w_1}}^{'})^2 = 0.999 \\cdot 0.001 + 0.001 \\cdot (-0.96)^2 = 0.00191904 \\\\\n",
        "s_2^2 &= \\beta_2 \\cdot s_2^1 + (1-\\beta_2) \\cdot ({f_{w_2}}^{'})^2 = 0.999 \\cdot 0.064 + 0.001 \\cdot (-7.2)^2 = 0.0698624\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- **STEP4**: tính toán bias-correction \\\\\n",
        "$$\n",
        "\\begin{aligned}\n",
        "v_{1corr} &= \\frac{v_1^2}{1-({\\beta_1})^2} = \\frac{-0.186}{1-0.9^2} = \\frac{-0.186}{0.19} = -0.9789 \\\\\n",
        "v_{2corr} &= \\frac{v_2^2}{1-({\\beta_1})^2} = \\frac{-1.44}{1-0.9^2} = \\frac{-1.44}{0.19} = -7.5789 \\\\\n",
        "s_{1corr} &= \\frac{s_1^2}{1-({\\beta_2})^2} = \\frac{0.00191904}{1-0.999^2} = \\frac{0.00191904}{0.001999} = 0.9597 \\\\\n",
        "s_{2corr} &= \\frac{s_2^2}{1-({\\beta_2})^2} = \\frac{0.0698624}{1-0.999^2} = \\frac{0.0698624}{0.001999} = 34.9545\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- **STEP5**: cập nhật trọng số w \\\\\n",
        "$$\n",
        "\\begin{aligned}\n",
        "w_1^3 &= w_1^2 - \\alpha \\cdot \\frac{v_{1corr}}{\\sqrt[2]{s_{1corr}} + \\epsilon} = -4.8 - 0.2 \\cdot \\frac{-0.9789}{\\sqrt[2]{0.9597} + 10^{-6}}\n",
        "= -4.8 + 0.2 \\cdot 0.9989 = -4.8 + 0.1998 = -4.6002 \\\\\n",
        "w_2^3 &= w_2^2 - \\alpha \\cdot \\frac{v_{2corr}}{\\sqrt[2]{s_{2corr}} + \\epsilon} = -1.8 - 0.2 \\cdot \\frac{-7.5789}{\\sqrt[2]{34.9545} + 10^{-6}}\n",
        "= -1.8 + 0.2 \\cdot 1.284 = -1.8 + 0.2568 = -1.5432\n",
        "\\end{aligned}\n",
        "$$"
      ],
      "metadata": {
        "id": "3oWIQ_aSX2I9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O7_IejwLXtdu"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def df_w(W):\n",
        "    \"\"\"\n",
        "    Thực hiện tính gradient của dw1 và dw2\n",
        "    Arguments:\n",
        "    W -- np.array [w1, w2]\n",
        "    Returns:\n",
        "    dW -- np.array [dw1, dw2], array chứa giá trị đạo hàm theo w1 và w2\n",
        "    \"\"\"\n",
        "    W = np.asarray(W)\n",
        "    dW = np.array([0.2, 4])*W\n",
        "    return dW"
      ],
      "metadata": {
        "id": "KSmpiq1uX6pF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Adam(W, dW, lr, V, S, beta1 = 0.9, beta2 = 0.999, t = 1):\n",
        "    \"\"\"\n",
        "    Thực hiện thuật tóan Adam để update w1 và w2\n",
        "    Arguments:\n",
        "    W -- np.array: [w1, w2]\n",
        "    dW -- np.array: [dw1, dw2], array chứa giá trị đạo hàm theo w1 và w2\n",
        "    lr -- float: learning rate\n",
        "    V -- np.array: [v1, v2] Exponentially weighted averages gradients\n",
        "    S -- np.array: [s1, s2] Exponentially weighted averages bình phương gradients\n",
        "    beta1 -- float: hệ số long-range average cho V\n",
        "    beta2 -- float: hệ số long-range average cho S\n",
        "    t -- int: lần thứ t update (bắt đầu bằng 1)\n",
        "    Returns:\n",
        "    W -- np.array: [w1, w2] w1 và w2 sau khi đã update\n",
        "    V -- np.array: [v1, v2] Exponentially weighted averages gradients sau khi đã cập nhật\n",
        "    S -- np.array: [s1, s2] Exponentially weighted averages bình phương gradients sau khi đã cập nhật\n",
        "    \"\"\"\n",
        "    epsilon = 1e-6\n",
        "\n",
        "    V = beta1*V + (1-beta1)*dW\n",
        "    S = beta2*S + (1-beta2)*(dW**2)\n",
        "    V_hat = V/(1-beta1**t)\n",
        "    S_hat = S/(1-beta2**t)\n",
        "    W = W - lr*V_hat/(np.sqrt(S_hat + epsilon))\n",
        "\n",
        "    return W, V, S"
      ],
      "metadata": {
        "id": "7UliFdQxX8Kc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_p1(optimizer, lr, epochs):\n",
        "    \"\"\"\n",
        "    Thực hiện tìm điểm minimum của function (1) dựa vào thuật toán\n",
        "    được truyền vào từ optimizer\n",
        "    Arguments:\n",
        "    optimize : function thực hiện thuật toán optimization cụ thể\n",
        "    lr -- float: learning rate\n",
        "    epochs -- int: số lượng lần (epoch) lặp để tìm điểm minimum\n",
        "    Returns:\n",
        "    results -- list: list các cặp điểm [w1, w2] sau mỗi epoch (mỗi lần cập nhật)\n",
        "    \"\"\"\n",
        "    # initial\n",
        "    W = np.array([-5, -2], dtype=np.float32)\n",
        "    V = np.array([0, 0], dtype=np.float32)\n",
        "    S = np.array([0, 0], dtype=np.float32)\n",
        "    results = [W]\n",
        "\n",
        "    for i in range(epochs):\n",
        "        dW = df_w(W)\n",
        "        W, V, S = optimizer(W, dW, lr, V, S, beta1 = 0.9, beta2 = 0.999, t = i+1)\n",
        "        results.append(W)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "dbIrRWI7X9rH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_p1(Adam, lr = 0.2, epochs = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TktxyGokX_K8",
        "outputId": "2e4408e9-632f-4e0e-fb72-b75f79fa527b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-5., -2.], dtype=float32),\n",
              " array([-4.8000001, -1.8      ]),\n",
              " array([-4.60025458, -1.60082446]),\n",
              " array([-4.40094818, -1.40317255]),\n",
              " array([-4.20227724, -1.20787812]),\n",
              " array([-4.00444983, -1.01592732]),\n",
              " array([-3.80768579, -0.82847292]),\n",
              " array([-3.61221664, -0.64684142]),\n",
              " array([-3.41828545, -0.47252746]),\n",
              " array([-3.22614653, -0.30716913]),\n",
              " array([-3.03606497, -0.15249832]),\n",
              " array([-2.84831603, -0.01026302]),\n",
              " array([-2.66318433,  0.11787577]),\n",
              " array([-2.48096283,  0.23046186]),\n",
              " array([-2.30195156,  0.32635894]),\n",
              " array([-2.12645613,  0.40484216]),\n",
              " array([-1.95478597,  0.46564981]),\n",
              " array([-1.7872523 ,  0.50898816]),\n",
              " array([-1.62416583,  0.53549455]),\n",
              " array([-1.46583419,  0.54617153]),\n",
              " array([-1.31255919,  0.54230818]),\n",
              " array([-1.16463376,  0.52540208]),\n",
              " array([-1.02233886,  0.49709058]),\n",
              " array([-0.88594013,  0.45909505]),\n",
              " array([-0.75568468,  0.41317772]),\n",
              " array([-0.63179773,  0.36110878]),\n",
              " array([-0.51447945,  0.30464032]),\n",
              " array([-0.40390206,  0.2454839 ]),\n",
              " array([-0.30020707,  0.18528898]),\n",
              " array([-0.20350296,  0.12562052]),\n",
              " array([-0.11386333,  0.06793506])]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}