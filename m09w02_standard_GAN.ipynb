{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard-GAN with MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chuẩn bị dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import các thu viện cần thiết\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:14<00:00, 679kB/s] \n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 119kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 826kB/s] \n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 290kB/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "image_size = 64\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root='data', train=True, transform=transforms, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: torch.Size([32, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Lấy một batch từ data_loader\n",
    "images, labels = next(iter(data_loader))\n",
    "\n",
    "# In kích thước của batch và ảnh\n",
    "print(f\"Batch size: {images.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xây dựng model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xây dựng Generator bằng MLP \n",
    "# layer cuối gần cuối có 1024 neuron, layer cuối cùng có ảnh có kích thước 64x64\n",
    "# reshape lại ảnh thành 64x64 (1 channel)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise, latent_dim, image_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(1024, image_size * image_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z: Tensor) -> Tensor:\n",
    "        output = self.gen(z)\n",
    "        output =  output.view(output.size(0), 1, image_size, image_size)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(image_size * image_size, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.disc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "latent_dim = 32\n",
    "generator = Generator(noise=torch.randn, latent_dim=latent_dim, image_size=image_size).to(device)\n",
    "discriminator = Discriminator(image_size=image_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "# Khởi tạo các tham số\n",
    "generator_optimal = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "discriminator_optimal = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import GradScaler, autocast\n",
    "scaler = GradScaler(device='cuda')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m d_losses\u001b[38;5;241m.\u001b[39mappend(d_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     24\u001b[0m discriminator_optimal\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# set tất cả các trong số về 0\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#d_loss.backward() # tính gradient\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#discriminator_optimal.step() # cập nhật các tham số\u001b[39;00m\n\u001b[0;32m     28\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(discriminator_optimal)\n",
      "File \u001b[1;32mc:\\Users\\lamxu\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lamxu\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lamxu\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g_losses = []\n",
    "d_losses = []\n",
    "critertion = nn.BCEWithLogitsLoss()\n",
    "image_size = 64\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        images = images.to(device)\n",
    "        real_labels = torch.ones(images.size(0),1).to(device)\n",
    "        fake_labels = torch.zeros(images.size(0),1).to(device)\n",
    "\n",
    "        #train Discriminator\n",
    "        noise = torch.randn(images.size(0), latent_dim).to(device)\n",
    "        fake_images = generator(noise)\n",
    "        with autocast(device_type='cuda'):\n",
    "            real_outputs = discriminator(images)\n",
    "            fake_outputs = discriminator(fake_images)\n",
    "\n",
    "            d_loss_real = critertion(real_outputs, real_labels)\n",
    "            d_loss_fake = critertion(fake_outputs, fake_labels)\n",
    "            d_loss = (d_loss_real + d_loss_fake)/2\n",
    "        d_losses.append(d_loss.item())\n",
    "\n",
    "        discriminator_optimal.zero_grad() # set tất cả các trong số về 0\n",
    "        scaler.scale(d_loss).backward()\n",
    "        #d_loss.backward() # tính gradient\n",
    "        #discriminator_optimal.step() # cập nhật các tham số\n",
    "        scaler.step(discriminator_optimal)\n",
    "        scaler.update()\n",
    "\n",
    "\n",
    "        #train Generator\n",
    "        noise = torch.randn(images.size(0), latent_dim).to(device)\n",
    "        with autocast(device_type='cuda'):\n",
    "            fake_images = generator(noise)\n",
    "            outputs = discriminator(fake_images)\n",
    "            # tính loss -> làm cho ảnh ảo giống ảnh thật\n",
    "            g_loss = critertion(outputs, real_labels) # đánh giá ảnh ảo với nhãn thật\n",
    "            g_losses.append(g_loss.item())\n",
    "\n",
    "        generator_optimal.zero_grad()\n",
    "        scaler.scale(g_loss).backward()\n",
    "        #g_loss.backward()\n",
    "        #generator_optimal.step()\n",
    "        scaler.step(generator_optimal)\n",
    "        scaler.update()\n",
    "\n",
    "    g_loss = sum(g_losses)/len(g_losses)\n",
    "    d_loss = sum(d_losses)/len(d_losses)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Generator Loss: {g_loss:.4f}, Discriminator Loss: {d_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA RTX A500 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Kiểm tra CUDA có khả dụng không\n",
    "print(torch.cuda.current_device())  # Kiểm tra GPU hiện tại\n",
    "print(torch.cuda.get_device_name(0))  # Tên GPU đang sử dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, _) in enumerate(data_loader):\n",
    "        images = images.to(device)\n",
    "        real_labels = torch.ones(images.size(0), 1).to(device)\n",
    "        fake_labels = torch.zeros(images.size(0), 1).to(device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        noise = torch.randn(images.size(0), latent_dim).to(device)\n",
    "        fake_images = generator(noise)\n",
    "        real_outputs = discriminator(images)\n",
    "        fake_outputs = discriminator(fake_images)\n",
    "\n",
    "        d_loss_real = critertion(real_outputs, real_labels)\n",
    "        d_loss_fake = critertion(fake_outputs, fake_labels)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        discriminator.zero_grad()\n",
    "        d_loss.backward()\n",
    "        discriminator_optim.step()\n",
    "\n",
    "        # Train Generator\n",
    "        noise = torch.randn(images.size(0), latent_dim).to(device)\n",
    "        fake_images = generator(noise)\n",
    "        outputs = discriminator(fake_images)\n",
    "        g_loss = critertion(outputs, real_labels)\n",
    "\n",
    "        generator.zero_grad()\n",
    "        g_loss.backward()\n",
    "        generator_optim.step()\n",
    "\n",
    "        g_losses.append(g_loss.item())\n",
    "        d_losses.append(d_loss.item())\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Batch [{i}/{len(data_loader)}], d_loss: {d_loss.item()}, g_loss: {g_loss.item()}\")\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        save_image(fake_images, f\"gan_images_{epoch}.png\")\n",
    "generator = Generator(1, latent_dim, image_size).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
